#!/usr/bin/env python3
"""
Automated internal tool to create UCVM-compatible digital elevation model.

This file creates a UCVM-compatible digital elevation model from USGS GridFloat data. The data set
that this script reads from is elevation data sampled at 1/3 arc-second resolution directly from the
USGS website: nationalmap.gov. In there, one can get various data. This reads data from 1/3
arc-second DEM (3DEP).

It also encodes the background ETOPO1 map which is the fallback for where there is no detailed
information from the National Map.

Copyright:
    Southern California Earthquake Center

Developer:
    David Gill <davidgil@usc.edu>
"""
# Python Imports
import fnmatch
import os
import re
import struct
import sys

# Package Imports
import tables
import numpy as np

try:
    import mpl_toolkits.basemap.pyproj as pyproj
except ImportError as the_err:
    print("UCVM requires PyProj to be installed. Please install PyProj and then re-run \
           this script.")
    pyproj = None  # Needed to remove the warning in PyCharm
    raise

# UCVM Imports
from ucvm.src.framework.ucvm import UCVM


def usage() -> None:
    """
    Prints out the usage information for this utility.

    Returns:
        None
    """
    UCVM.print_with_replacements(
        "\n"
        "ucvm_create_dem - UCVM Version [version]\n"
        "\n"
        "This utility creates a UCVM-compatible digital elevation model from 1/3 arc-second\n"
        "GridFloat files. These files can be downloaded directly from nationalmap.gov, a USGS\n"
        "website. This utility takes two parameters:\n"
        "\n"
        "-i, --input-dir d:     The directory containing the GridFloat files. Each file has name\n"
        "                       floatn[start latitude]w[start longitude].flt.\n"
        "-o, --output-file f:   The UCVM-compatible DEM file. This file is used by the DEM code\n"
        "                       to provide the elevation data.\n"
    )


def parse_usgs_header(usgs_header_file: str) -> dict:
    """
    Parses the USGS national map header files. We can then use this information to tile together
    the grid points and create the end result data file.

    Args:
        usgs_header_file (str): The header file location as a string.

    Returns:
        A dictionary containing all the header elements, with conversions to floats and ints done
        as necessary.
    """
    file_open = open(usgs_header_file, "r")
    parts = {}

    for line in file_open:
        tokens = line.split()
        parts[tokens[0]] = tokens[1]

    parts["cellsize"] = float(parts["cellsize"])
    parts["xllcorner"] = float(parts["xllcorner"])
    parts["yllcorner"] = float(parts["yllcorner"])
    parts["ncols"] = int(parts["ncols"])
    parts["nrows"] = int(parts["nrows"])

    file_open.close()

    return parts


def parse_noaa_header(bathymetry_header_file: str) -> dict:
    """
    Parses the NOAA bathymetry ArcGIS ASCII grid data header. We use this to tile the grid points
    to create the end result data file.

    Args:
        bathymetry_header_file: The header file location as a string.

    Returns:
        A dictionary containing all the header elements, with conversions to floats and ints done
        as necessary.
    """
    file_open = open(bathymetry_header_file, "r")
    parts = {}

    counter = 0
    while counter < 5:
        tokens = file_open.readline().split()
        parts[tokens[0]] = tokens[1]
        counter += 1

    parts["cellsize"] = float(parts["cellsize"])
    parts["xllcorner"] = float(parts["xllcenter"])
    parts["yllcorner"] = float(parts["yllcenter"])
    parts["ncols"] = int(parts["ncols"])
    parts["nrows"] = int(parts["nrows"])

    file_open.close()

    return parts


def main() -> int:
    """
    The main function which handles the creation of the UCVM-compatible DEM.

    Returns:
        Zero when successful. Exits with non-zero code if not.
    """
    try:
        options = UCVM.parse_options([
            {"short": "i", "long": "input-dir", "value": True, "required": True},
            {"short": "o", "long": "output-file", "value": True, "required": True},
            {"short": "r", "long": "register", "value": False, "required": False}
        ], usage)
    except ValueError as v_err:
        print("[ERROR]: " + str(v_err) + "\n")
        sys.exit(-1)

    print("\nUCVM Create DEM\n\nGetting file list...")

    # Get a list of all the files to convert.
    temp_file_list = [f for f in os.listdir(options["input-dir"])
                      if os.path.isfile(os.path.join(options["input-dir"], f))]

    out_file = tables.open_file(options["output-file"], mode="w")
    filters = tables.Filters(complevel=7, complib='blosc')

    class DEMHeader(tables.IsDescription):
        cellsize = tables.Float32Col(pos=0)
        xllcorner = tables.Float32Col(pos=1)
        yllcorner = tables.Float32Col(pos=2)
        numcols = tables.Int32Col(pos=3)
        numrows = tables.Int32Col(pos=4)

    for file in temp_file_list:
        # Handle the bathymetry data.
        if fnmatch.fnmatch(file, "etopo1_bed_g_f4.flt"):
            print("Creating data set from NOAA etopo1 bathymetry file " + file + "...")
            header = parse_noaa_header(os.path.join(options["input-dir"],
                                                    file.replace(".flt", ".hdr")))

            grp = out_file.create_group(out_file.root, "dem_etopo1")

            table_grp = out_file.create_table(grp, "metadata", DEMHeader)

            row = table_grp.row
            row["cellsize"] = header["cellsize"]
            row["xllcorner"] = header["xllcorner"]
            row["yllcorner"] = header["yllcorner"]
            row["numcols"] = header["ncols"]
            row["numrows"] = header["nrows"]
            row.append()
            table_grp.flush()

            arr = np.zeros((header["nrows"], header["ncols"]), dtype="<f8")

            # Now read in the floats.
            fin = open(os.path.join(options["input-dir"], file), "rb")

            for i in range(header["nrows"] - 1, -1, -1):
                for j in range(0, header["ncols"]):
                    bytes_val = fin.read(4)
                    input_data = struct.unpack('f', bytes_val)
                    arr[i][j] = input_data[0]

            data = out_file.create_earray(grp, "data", tables.Atom.from_dtype(arr.dtype),
                                          shape=(0, arr.shape[-1]), filters=filters,
                                          expectedrows=len(arr))

            for i in range(0, len(arr)):
                data.append(arr[i][None])

            fin.close()

        if fnmatch.fnmatch(file, "floatn*w*_1.flt"):
            print("Creating data set from USGS National Map file " + file + "...")
            header = parse_usgs_header(os.path.join(options["input-dir"],
                                                    file.replace(".flt", ".hdr")))
            match = re.match(r"floatn(\d+)([we])(\d+)_1.flt", file)

            lat = int(match.group(1)) - 1

            multiplier = 1
            if match.group(2) == "w":
                multiplier = -1

            lon = multiplier * int(match.group(3))

            grp = out_file.create_group(out_file.root, "dem_nationalmap_" + str(-1 * lon) +
                                        "_" + str(lat))

            table_grp = out_file.create_table(grp, "metadata", DEMHeader)

            # Attach the metadata to it.
            row = table_grp.row
            row["cellsize"] = header["cellsize"]
            row["xllcorner"] = header["xllcorner"]
            row["yllcorner"] = header["yllcorner"]
            row["numcols"] = header["ncols"]
            row["numrows"] = header["nrows"]
            row.append()
            table_grp.flush()

            arr = np.zeros((header["nrows"], header["ncols"]), dtype="<f8")

            # Now read in the floats.
            fin = open(os.path.join(options["input-dir"], file), "rb")

            for i in range(header["nrows"] - 1, -1, -1):
                for j in range(0, header["ncols"]):
                    bytes_val = fin.read(4)
                    input_data = struct.unpack('f', bytes_val)
                    arr[i][j] = input_data[0]

            data = out_file.create_earray(grp, "data", tables.Atom.from_dtype(arr.dtype),
                                          shape=(0, arr.shape[-1]), filters=filters,
                                          expectedrows=len(arr))

            for i in range(0, len(arr)):
                data.append(arr[i][None])

            fin.close()

    out_file.close()

    return 0

if __name__ == "__main__":
    sys.exit(main())
